{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MIDP","text":"<p>MIDP stands for Multi-modal Intelligent Document Processing. Orkid MIDP platform help non-technical users to build LLM components able to summarize, classify and extract information from unstructured documents.  </p> <p>To know more visit orkid.io.</p>"},{"location":"api-reference/","title":"API Reference","text":""},{"location":"faq/","title":"FAQ","text":""},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#introduction","title":"Introduction","text":"<p>The Orkid.io MIDP API allows you to programmatically interact with your organization data, at minimum it allows you to:  </p> <ul> <li>Invite users to your organization (memberships).</li> <li>Create projects within your organization.</li> <li>Create processing artifacts inside projects, i.e. document categories, classifiers, extractors.</li> <li>Upload documents (flow or step modes).</li> <li>Upload big document files by pre-signed URL.</li> <li>Detect text and layout info within documents (OCR).</li> <li>Create documents data extraction schemas.</li> <li>Classify documents.</li> <li>Split multi-document files and extract sub-documents.</li> <li>Extract information from documents.</li> </ul>"},{"location":"getting-started/#quick-start","title":"Quick start","text":"<p>This quick start guide covers the basics to use the MIDP API, from authentication to document processing. After going through the guide you should be able to perform the most common MIDP API operations. For a complete list of all supported API operations, check the complete API documentation and reference.</p>"},{"location":"getting-started/#install-curl","title":"Install curl","text":"<p><code>curl</code> should already be installed by default in you OS if you use MacOS or any Linux distribution, if that's not the case you can grab it from curl.haxx.se.</p>"},{"location":"getting-started/#use-the-api-from-windows","title":"Use the API from Windows","text":""},{"location":"getting-started/#create-an-account","title":"Create an account","text":"<p>Contact support@orkid.io to get a registered in MIDP. Once registration is confirmed, you will receive an email asking to reset your password, after which we'll send you a <code>client id</code>. At this time you are all set to authenticate and start using the MIDP API.</p> <p>Note</p> <p>Self-service account creation is a work in progress, we'll update the docs once it becomes available.</p>"},{"location":"getting-started/#authenticate","title":"Authenticate","text":"<pre><code>curl --location 'https://cognito-idp.eu-west-1.amazonaws.com/' \\\n--header 'Content-Type: application/x-amz-json-1.1' \\\n--header 'X-Amz-Target: AWSCognitoIdentityProviderService.InitiateAuth' \\\n--data-raw '{\n    \"AuthParameters\" : {\n        \"USERNAME\" : \"{{username}}\",\n        \"PASSWORD\" : \"{{password}}\"\n    },\n    \"AuthFlow\" : \"USER_PASSWORD_AUTH\",\n    \"ClientId\" : \"{{clientId}}\"\n}'\n</code></pre>"},{"location":"getting-started/#auth-parameters","title":"Auth Parameters","text":"<pre><code>{\n    \"AuthParameters\" : {\n        \"USERNAME\" : \"{{username}}\", // email used to register in Orkid.io\n        \"PASSWORD\" : \"{{password}}\" // password used to register in Orkid.io\n    },\n    \"AuthFlow\" : \"USER_PASSWORD_AUTH\", // authentication flow\n    \"ClientId\" : \"{{clientId}}\" // clientId received after the registration in Orkid.io\n}\n</code></pre>"},{"location":"getting-started/#response","title":"Response","text":"<pre><code>{\n    \"AuthenticationResult\": {\n        \"AccessToken\": \"(...)\", // access token to send as a header in consecutive API calls\n        \"ExpiresIn\": 3600, // by default token expires in 1h\n        \"IdToken\": \"(...)\",\n        \"RefreshToken\": \"(...)\", // refresh token\n        \"TokenType\": \"Bearer\"\n    },\n    \"ChallengeParameters\": {}\n}\n</code></pre>"},{"location":"getting-started/#token-use","title":"Token use","text":"<p>All MIDP API endpoints require authentication prior using them. In order to access API endpoints, you must send the header <code>'Authorization: Bearer &lt;AccessToken&gt;'</code>. </p>"},{"location":"getting-started/#base-url","title":"Base Url","text":"<p>Orkid.io MIDP API is accesible via https://api.midp.taiger.io, make sure to replace this value in the <code>baseUrl</code> variable in <code>curl</code> commands.</p>"},{"location":"getting-started/#create-a-project","title":"Create a project","text":"<p>A project is a container for documents, extraction schemas, classifiers and extractors configuration. The first step to use the MIDP API after getting registered in an Organisation is to create a new project. You can create a project through the API with:</p> <pre><code>curl -X 'POST' \\\n  '{{baseUrl}}/projects' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer &lt;AccessToken&gt;' \\\n  -H 'x-organization-id: {{organization_id}}' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"name\": \"string\"\n}'\n</code></pre>"},{"location":"getting-started/#create-a-document-category","title":"Create a document category","text":"<p>Document categories reprsent the different types of documents a project can process, e.g. invoices, contracts, etc. The categories will be used by the project's classifiers and extractors to properly select the underlying LLM to process the incoming documents. You can create a category through the API with: <pre><code>curl -X 'POST' \\\n  '{{baseUrl}}/projects/{{project_id}}/categories' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer &lt;AccessToken&gt;' \\\n  -H 'x-organization-id: {{organization_id}}' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"name\": \"string\",\n  \"description\": \"string\"\n}'\n</code></pre></p>"},{"location":"getting-started/#create-an-extractor","title":"Create an extractor","text":"<pre><code>curl -X 'POST' \\\n  '{{baseUrl}}/projects/{{project_id}}/extractors' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer &lt;AccessToken&gt;' \\\n  -H 'x-organization-id: {{organization_id}}' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"name\": \"string\",\n  \"ocr_mode\": \"text\"\n}'\n</code></pre>"},{"location":"getting-started/#create-a-datapoint-extraction-schema","title":"Create a datapoint extraction schema","text":"<p>The schema of the data to be extracted will determine the output value parsing of each datapoint as well as the number of possible instances of each.</p> <ul> <li>d_cardinality: How many values do you expect to extract from this datapoint? Cardinality can be <code>one</code> or <code>many</code>.</li> <li> <p>d_type: Which type do you want the datapoint returns its value in? Types can be:  </p> <ul> <li>object: JSON like object, e.g.  <pre><code>{\"name\": \"John\", \"age\": 25} // Person object\n</code></pre></li> <li>number: A numeric value e.g. <code>32</code> or a string like <code>\"forty-four\"</code> will produce the numeric outputs: <code>32</code> and <code>44</code> respectively. Currency values applies as well.</li> <li>bool: Binary statements, e.g. the statement: <code>\"the invoice is due\"</code> will return <code>True</code> if the condition is met, <code>False</code> otherwise. </li> <li>text: Any text value, e.g. <code>\"the name of the person\"</code> will return <code>\"John Doe\"</code> text value.</li> </ul> </li> <li> <p>extractor_id: The extractor you want to associate the new datapoint with.</p> </li> </ul> <pre><code>curl -X 'POST' \\\n  '{{baseUrl}}/projects/{{project_id}}/datapoints?d_cardinality=one&amp;d_type=text&amp;extractor_id={{extractor_id}}' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer &lt;AccessToken&gt;' \\\n  -H 'x-organization-id: {{organization_id}}' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"name\": \"ID number\",\n  \"description\": \"Identification number\",\n  \"required\": true\n}'\n</code></pre> <p>Check the successful datapoint response for the expected output.</p>"},{"location":"getting-started/#upload-a-document","title":"Upload a document","text":"<p>Uploading a document requieres the definition of certain params:</p> <ul> <li>collection: Document collection you want to upload the document to, choose between (dev, valid, test).</li> <li>classifier_id: (Optional) The id of the classifier you want to use to classify the uploaded document.</li> <li>channel: The channel param indicates the workflow the document is going to follow after uploading. Step channel will upload the document, detect its OCR content and stop. The Flow channel, aditionally to OCR, will classify (if applicable) and extract the information from a the document if there's a live extractor configured for this project. </li> <li>category_id: The id of the category the uploaded document belongs to. Optional if no classifier id is provided.</li> </ul> <p><pre><code>curl -X 'POST' \\\n  '{{baseUrl}}/projects/{{project_id}}/documents/uploaded?collection=dev&amp;channel=FLOW&amp;category_id={{category_id}}' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer &lt;AccessToken&gt;' \\\n  -H 'x-organization-id: {{organization_id}}' \\\n  -H 'Content-Type: multipart/form-data' \\\n  -F 'file=@Document.pdf;type=application/pdf'\n</code></pre> Check the successful document response for the expected output.</p>"},{"location":"getting-started/#extract-information-from-uploaded-document","title":"Extract information from uploaded document","text":"<p>Uploading a document using the FLOW channel will take care of the extraction if the selected category id is linked to a live extractor. The further description of the flow channel and live extractors are outside the scope of this quick start guide. MIDP API also allows a much simpler extraction use case where the can indicate the extractor directly, this is the case shown next. </p> <p><pre><code>curl -X 'PUT' \\\n  '{{baseUrl}}/projects/{{project_id}}/documents/{{document_id}}/extracted?extractor_id={{extractor_id}}' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer &lt;AccessToken&gt;' \\\n  -H 'x-organization-id: {{organization_id}}'\n</code></pre> Check the successful document response for the expected output.</p>"},{"location":"getting-started/#retrieve-extracted-data","title":"Retrieve extracted data","text":"<p>Once a document have been processed, the extracted information can be retrieved by document id. <pre><code>curl -X 'GET' \\\n  '{{baseUrl}}/projects/{{project_id}}/documents/{{document_id}}' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer &lt;AccessToken&gt;' \\\n  -H 'x-organization-id: {{organization_id}}'\n</code></pre></p>"},{"location":"getting-started/#successful-datapoint-response","title":"Successful <code>datapoint</code> response","text":"<pre><code>{\n  \"id\": 0,\n  \"name\": \"string\",\n  \"description\": \"string\",\n  \"context_size\": 0,\n  \"parent_id\": 0,\n  \"d_cardinality\": \"many\",\n  \"d_type\": \"object\",\n  \"normalized\": \"string\",\n  \"options\": {\n    \"sections\": [\n      \"string\"\n    ]\n  },\n  \"project_id\": 0,\n  \"required\": true\n}\n</code></pre>"},{"location":"getting-started/#successful-document-response","title":"Successful <code>document</code> response","text":"<pre><code>{\n  \"id\": 0,  // document id\n  \"chunks\": 0, // number of chunks, i.e. document fragments\n  \"name\": \"string\", // document name\n  \"uuid\": \"3fa85f64-5717-4562-b3fc-2c963f66afa6\", // document uuid\n  \"ocr_provider\": \"aws\", // ocr provider used to get the contents of the document\n  \"collection\": \"dev\", // collection to which the document belongs\n  \"category_id\": 0, // category id associated with this document, manually specfified in this case\n  \"status\": \"UPLOADED\", // status of the document\n  \"location\": \"string\", // document file path in S3\n  \"ocr_output\": \"string\", // ocr content file path in S3\n  \"ocr_job_id\": \"string\", // AWS Textract JobID \n  \"ocr_mode\": \"string\", // selected ocr mode from &lt;text&gt;, &lt;layout&gt;, &lt;table&gt;.\n  \"error\": \"string\", // last error recorded if something went wrong\n  \"channel\": \"FLOW\", // processing channel\n  \"project_id\": 0, // project id this document belongs to\n  \"pred_category_id\": 0, // predicted category if inferred by classifier\n  \"classifier_id\": 0, // classifier id used with this document\n  \"extractor_id\": 0, // extactor id used with this document\n  \"created_at\": \"2024-09-23T16:53:20.048Z\", // creation (Uploaded) timestamp \n  \"updated_at\": \"2024-09-23T16:53:20.048Z\", // last update timestamp\n  \"category_supervision_status\": \"string\",\n  \"supervision_status\": \"string\", // human-in-the-loop status \n  \"extractions\": [], // information extracted from this document\n  \"cls_metrics\": { // classification metrics\n    \"accuracy\": 0,\n    \"precision\": 0,\n    \"recall\": 0,\n    \"f1\": 0\n  },\n  \"ext_metrics\": { // extraction metrics\n    \"accuracy\": 0,\n    \"precision\": 0,\n    \"recall\": 0,\n    \"f1\": 0\n  }\n}\n</code></pre>"},{"location":"overview/","title":"Overview","text":""},{"location":"overview/#http-and-rest","title":"HTTP and REST","text":""},{"location":"overview/#http-verbs-operations","title":"HTTP Verbs (Operations)","text":""},{"location":"overview/#base-url","title":"Base URL","text":""},{"location":"overview/#authentication","title":"Authentication","text":""},{"location":"overview/#pagination","title":"Pagination","text":""},{"location":"overview/#filtering","title":"Filtering","text":""},{"location":"overview/#rate-limits","title":"Rate Limits","text":""},{"location":"overview/#errors","title":"Errors","text":"<pre><code>E001 = \"Document not found\"\nE002 = \"Project not found\"\nE003 = \"Datapoint not found\"\nE004 = \"Datapoint {child_id} already assigned to parent {child_parent_id}\"\nE005 = \"Trying to add a datapoint to a child datapoint. Only one level of nesting between datapoints is supported\"\nE006 = \"Child datapoint: {child_name} already added to parent: {parent_name}\"\nE007 = \"A datapoint cannot be parent of itself\"\nE008 = \"Can only add type {datapoint_type} to {parent_d_cardinality} datapoints\"\nE009 = \"Child datapoints cannot contain examples, please create example at parent level\"\nE010 = \"Example already exist for this datapoint\"\nE011 = \"Example not found\"\nE012 = \"Datapoint structure with shape: {d_cardinality} -&gt; {d_type} -&gt; {d_format} is not defined\"\nE013 = \"Datapoint {datapoint_name} already exist\"\nE014 = \"Cannot add children to child datapoints\"\nE015 = \"Cannot add children to {d_cardinality} datapoints\"\nE016 = \"Project name cannot be empty\"\nE017 = \"Embedded document with uuid: {uuid} not found in vector store\"\nE018 = \"Project already exists with this name for this user\"\nE019 = \"Document not found\"\nE020 = \"Extraction not found\"\nE021 = \"Project collection name already exist\"\nE022 = \"Extraction value and context already exist for this document\"\nE023 = \"Extractor does not contain any defined datapoints\"\nE024 = \"Datapoint of type Object must have nested datapoints\"\nE025 = \"Incorrect datapoint structure. Please use the following structure: 'value': {correct_structure}\"\nE026 = \"Value cannot be empty for a supervised extraction\"\nE027 = \"Not supported file extension: {ext}. Supported file extensions are: {supported}\"\nE028 = \"S3 Exception: {e}\"\nE029 = \"Project has no documents in S3\"\nE030 = \"Current project name and new name provided are the same. Please pick a new name\"\nE031 = \"Extractor not found\"\nE032 = \"Extractor already exist\"\nE033 = \"Classifier already exist\"\nE034 = \"Classifier not found\"\nE035 = \"Classifier does not contain any categories, please define at least 2\"\nE036 = \"Category already exist in this project\"\nE037 = \"Category not found\"\nE038 = \"Development &amp; Validation documents must be tagged with a category\"\nE039 = \"Category not in the project\"\nE040 = \"Classifier not in the project\"\nE041 = \"Datapoint {datapoint} already in extractor {extractor}\"\nE042 = \"Empty request body, please enter the correct payload data\"\nE043 = \"Invalid OCR Job Id\"\nE044 = \"OCR text detection failed. Error: {message}\"\nE045 = \"Can only extract information from classified or previously extracted documents\"\nE046 = \"Category not found in this Extractor\"\nE047 = \"Can only extract information from classified, extracted or detected documents\"\nE048 = \"Extraction status must be either predicted, validated, supervised or rejected\"\nE049 = \"Validated document cannot be manually edited at the same time\"\nE050 = \"OpenAI Error: {error}\"\nE051 = \"Document with name: {file_name} already exist in this project\"\nE052 = \"Flow processing requires a classifier or a category\"\nE053 = \"Document must have a category in order to extract\"\nE054 = \"You need at least one live extractor configured in this project\"\nE055 = \"Document detection is already in progress\"\nE056 = \"Document is not currently in progress for detection\"\nE057 = \"Can only classify documents that are detected, classified, not classified or extracted\"\nE058 = \"Cannot classify documents in dev collection\"\nE059 = \"Classifier discriminant should have a description and/or sections\"\nE060 = \"RAG classifier needs at least one dev document\"\nE061 = \"Fine-tuning a classifier requires at least 100 dev documents\"\nE062 = \"Fine-tuning capacity error, try again later or select a different instance type\"\nE063 = \"No model has been created for this classifier, please generate datasets to start the process.\"\nE064 = \"Last fine-tuning job failed\"\nE065 = \"Fine-tuning stopped\"\nE066 = \"Fine-tuning still in progress\"\nE067 = \"Model already deployed. Please finetune a new version and try again\"\nE068 = \"Model {model} is not deployed.\"\nE069 = \"OCR analysis format is wrong, a re-analysis of the document is required\"\nE070 = \"Cannot deploy a model without fine-tuning first, please finetune the model and try again\"\nE071 = \"Please make sure to classify the the complete DEV set for this classifier before generating the dataset\"\nE072 = \"Could not find discriminants. Currently finetuned models only work for classifiers using discriminants\"\nE073 = \"Datasets not ready for fine-tuning, check datasets generation status\"\nE074 = \"Model not ready for predictions (Confidence map). Use RAG or configure finetuned model confidence map\"\nE075 = \"Can only finetune models with documents from DEV collection\"\nE076 = \"Batch not found\"\nE077 = \"The document can not be processed because it has no category\"\nE078 = \"Document classification text is empty\"\nE079 = \"Document category is required when supervising a document\"\nE080 = \"There is a batch transform in progress for this project and classifier, skipping\"\nE081 = \"User with email {email} already exist in this user pool\"\nE082 = \"User not found\"\nE083 = \"Organization not found\"\nE084 = \"Domain already registered\"\nE085 = \"Domain not registered, please contact support@orkid.io\"\nE086 = \"Membership already exist for this user and organization\"\nE087 = \"Role not found\"\nE088 = \"Please provide at least user email, id or uuid\"\nE089 = \"Membership not found for this user and organization\"\nE090 = \"The project does not belong to the organization\"\nE091 = \"The solution id must belongs to a project marked as 'solution'\"\nE092 = \"The specified solution has not been shared to your organization\"\nE093 = \"Dossier not found\"\nE094 = \"Dossier already exist\"\n</code></pre>"},{"location":"uploads/","title":"Document Uploading","text":""},{"location":"uploads/#simple-uploads","title":"Simple uploads","text":""},{"location":"uploads/#workflow-uploads","title":"Workflow uploads","text":""},{"location":"uploads/#classification","title":"Classification","text":""},{"location":"uploads/#extraction","title":"Extraction","text":""},{"location":"uploads/#splitting","title":"Splitting","text":""}]}